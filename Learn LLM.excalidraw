{
  "type": "excalidraw",
  "version": 2,
  "source": "https://excalidraw.com",
  "elements": [
    {
      "id": "qxXUoyX900HEZ5lIliMda",
      "type": "text",
      "x": 670,
      "y": 408,
      "width": 1524.2587890625,
      "height": 2592,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "a4",
      "roundness": null,
      "seed": 1903869531,
      "version": 1534,
      "versionNonce": 1994725429,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254097127,
      "link": null,
      "locked": false,
      "text": "LLM (Large Language Models) là các mô hình trí tuệ nhân tạo được huấn luyện trên lượng dữ liệu văn bản khổng lồ để hiểu và tạo ra ngôn ngữ tự nhiên. \nCác mô hình này dựa trên kiến trúc Transformer, được giới thiệu lần đầu trong bài báo \"Attention Is All You Need\" năm 2017.\n\nCơ chế hoạt động cơ bản\n\n1. Tokenization (Phân tách token)\nToken là đơn vị cơ bản mà LLM xử lý. \nMột token có thể là:\n- Một từ hoàn chỉnh (ví dụ: \"học\")\n- Một phần của từ (ví dụ: \"học_tập\" có thể được chia thành \"học\" và \"_tập\")\n- Một ký tự đơn lẻ (ví dụ: \"!\")\n- Một khoảng trắng\nCâu \"Tôi đang học về trí tuệ nhân tạo\" có thể được chia thành các token như:\n[\"Tôi\", \" đang\", \" học\", \" về\", \" trí\", \" tuệ\", \" nhân\", \" tạo\"]\n\nMỗi khi các bạn gửi một đoạn yêu cầu (chúng ta còn gọi là prompt), hệ thống sẽ tự động tách nhỏ chúng ra thành từng chunks nhỏ theo đúng thứ tự, chúng chính là token.\nCác token này được sắp xếp một chiều - theo chính xác thứ tự mà bạn input.\nTham khảo thêm: https://tiktokenizer.vercel.app/\n\n\n2. Token Stream (Luồng token)\nToken stream là dòng các token được xử lý tuần tự bởi mô hình. \nKhi bạn nhập một câu hỏi, nó được chuyển đổi thành một chuỗi token đầu vào. \nKhi mô hình tạo ra câu trả lời, nó tạo ra một chuỗi token đầu ra, mỗi token một lúc.\n\nVí dụ về token stream:\nĐầu vào: \"Thời tiết hôm nay thế nào?\"\nLuồng token đầu vào: [\"Thời\", \" tiết\", \" hôm\", \" nay\", \" thế\", \" nào\", \"?\"]\nLuồng token đầu ra: [\"Hôm\", \" nay\", \" trời\", \" nắng\", \" đẹp\", \",\", \" nhiệt\", \" độ\", \" khoảng\", \" 30\", \" độ\", \" C\", \".\"]\n\n==> Trong một conversation, cả bạn và AI sẽ cùng nhau maintain đoạn conversation đó. Conversation là 1 chuỗi token stream.\nChúng ta sẽ tiếp tục thêm các token vào chuỗi token stream này.\nChuỗi token stream này sẽ được reset khi chúng ta bắt đầu một conversation mới.\n\n3. Embedding (Biểu diễn vector)\nMỗi token được chuyển đổi thành một vector số học nhiều chiều (thường là hàng trăm hoặc hàng nghìn chiều). \nCác vector này nắm bắt ý nghĩa và ngữ cảnh của token.\n\nVí dụ: Các từ có nghĩa tương tự như \"tốt\" và \"hay\" sẽ có vector gần nhau trong không gian embedding.\n\n4. Cơ chế Attention (Cơ chế chú ý)\nCơ chế Attention là trái tim của LLM, cho phép mô hình tập trung vào các phần khác nhau của văn bản đầu vào khi tạo ra đầu ra.\n\nVí dụ: Trong câu \"Anh ấy nói rằng anh ấy sẽ đến muộn\", khi mô hình tạo ra từ \"muộn\", nó chú ý nhiều đến \"anh ấy\" và \"đến\" để hiểu ai sẽ đến muộn.\n\n5. Quá trình tạo văn bản (Text Generation)\nKhi tạo văn bản, LLM dự đoán token tiếp theo dựa trên tất cả các token trước đó. Quá trình này lặp lại cho đến khi hoàn thành câu trả lời.\n\nVí dụ về quá trình tạo văn bản:\n\nĐầu vào: \"Thủ đô của Việt Nam là\"\nMô hình dự đoán token tiếp theo với xác suất cao nhất là \" Hà\"\nTiếp theo là \" Nội\"\nVà có thể là dấu chấm \".\"\n\n\nCác khái niệm quan trọng khác\n1. Tham số (Parameters)\nTham số là các giá trị số học mà mô hình học được trong quá trình huấn luyện. LLM hiện đại có hàng tỷ đến hàng nghìn tỷ tham số.\n\nVí dụ: GPT-3 có 175 tỷ tham số, Claude 3 Opus có khoảng 1 nghìn tỷ tham số.\n\n2. Context Window (Cửa sổ ngữ cảnh)\nContext window là số lượng token tối đa mà mô hình có thể xử lý cùng một lúc. Nó quyết định \"bộ nhớ\" của mô hình.\n\nVí dụ: Nếu một mô hình có context window 8K tokens, nó có thể \"nhớ\" và xử lý khoảng 6000-8000 từ tiếng Việt cùng một lúc.\n\n3. Temperature (Nhiệt độ)\nTemperature là tham số điều chỉnh mức độ ngẫu nhiên trong đầu ra của mô hình.\n\nVí dụ:\n\nTemperature thấp (0.2): \"Hà Nội là thủ đô của Việt Nam.\"\nTemperature cao (0.8): \"Hà Nội, thành phố nghìn năm văn hiến, là trái tim và thủ đô của đất nước Việt Nam xinh đẹp.\"\n\n4. Fine-tuning (Tinh chỉnh)\nFine-tuning là quá trình điều chỉnh mô hình đã được huấn luyện trước để phù hợp với nhiệm vụ cụ thể.\n\nVí dụ: Một LLM tổng quát có thể được fine-tune để trở thành trợ lý y tế bằng cách huấn luyện thêm trên dữ liệu y khoa.\n\n\nVí dụ minh họa về cách LLM xử lý văn bản\n\nGiả sử bạn hỏi: \"Làm thế nào để nấu phở bò?\"\n\nTokenization: Câu hỏi được chia thành các token: [\"Làm\", \" thế\", \" nào\", \" để\", \" nấu\", \" phở\", \" bò\", \"?\"]\nEmbedding: Mỗi token được chuyển đổi thành vector số học.\nXử lý qua các lớp Transformer: Mô hình xử lý các token thông qua nhiều lớp transformer, áp dụng cơ chế attention để hiểu ngữ cảnh.\nTạo câu trả lời: Mô hình bắt đầu tạo ra câu trả lời, token một:\nDự đoán token đầu tiên: \"Để\"\nTiếp theo: \" nấu\"\nTiếp theo: \" phở\"\nTiếp theo: \" bò\"\nTiếp theo: \" ngon\"\n...\nQuá trình này tiếp tục cho đến khi hoàn thành câu trả lời hoặc đạt đến giới hạn token.",
      "fontSize": 20,
      "fontFamily": 6,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "LLM (Large Language Models) là các mô hình trí tuệ nhân tạo được huấn luyện trên lượng dữ liệu văn bản khổng lồ để hiểu và tạo ra ngôn ngữ tự nhiên. \nCác mô hình này dựa trên kiến trúc Transformer, được giới thiệu lần đầu trong bài báo \"Attention Is All You Need\" năm 2017.\n\nCơ chế hoạt động cơ bản\n\n1. Tokenization (Phân tách token)\nToken là đơn vị cơ bản mà LLM xử lý. \nMột token có thể là:\n- Một từ hoàn chỉnh (ví dụ: \"học\")\n- Một phần của từ (ví dụ: \"học_tập\" có thể được chia thành \"học\" và \"_tập\")\n- Một ký tự đơn lẻ (ví dụ: \"!\")\n- Một khoảng trắng\nCâu \"Tôi đang học về trí tuệ nhân tạo\" có thể được chia thành các token như:\n[\"Tôi\", \" đang\", \" học\", \" về\", \" trí\", \" tuệ\", \" nhân\", \" tạo\"]\n\nMỗi khi các bạn gửi một đoạn yêu cầu (chúng ta còn gọi là prompt), hệ thống sẽ tự động tách nhỏ chúng ra thành từng chunks nhỏ theo đúng thứ tự, chúng chính là token.\nCác token này được sắp xếp một chiều - theo chính xác thứ tự mà bạn input.\nTham khảo thêm: https://tiktokenizer.vercel.app/\n\n\n2. Token Stream (Luồng token)\nToken stream là dòng các token được xử lý tuần tự bởi mô hình. \nKhi bạn nhập một câu hỏi, nó được chuyển đổi thành một chuỗi token đầu vào. \nKhi mô hình tạo ra câu trả lời, nó tạo ra một chuỗi token đầu ra, mỗi token một lúc.\n\nVí dụ về token stream:\nĐầu vào: \"Thời tiết hôm nay thế nào?\"\nLuồng token đầu vào: [\"Thời\", \" tiết\", \" hôm\", \" nay\", \" thế\", \" nào\", \"?\"]\nLuồng token đầu ra: [\"Hôm\", \" nay\", \" trời\", \" nắng\", \" đẹp\", \",\", \" nhiệt\", \" độ\", \" khoảng\", \" 30\", \" độ\", \" C\", \".\"]\n\n==> Trong một conversation, cả bạn và AI sẽ cùng nhau maintain đoạn conversation đó. Conversation là 1 chuỗi token stream.\nChúng ta sẽ tiếp tục thêm các token vào chuỗi token stream này.\nChuỗi token stream này sẽ được reset khi chúng ta bắt đầu một conversation mới.\n\n3. Embedding (Biểu diễn vector)\nMỗi token được chuyển đổi thành một vector số học nhiều chiều (thường là hàng trăm hoặc hàng nghìn chiều). \nCác vector này nắm bắt ý nghĩa và ngữ cảnh của token.\n\nVí dụ: Các từ có nghĩa tương tự như \"tốt\" và \"hay\" sẽ có vector gần nhau trong không gian embedding.\n\n4. Cơ chế Attention (Cơ chế chú ý)\nCơ chế Attention là trái tim của LLM, cho phép mô hình tập trung vào các phần khác nhau của văn bản đầu vào khi tạo ra đầu ra.\n\nVí dụ: Trong câu \"Anh ấy nói rằng anh ấy sẽ đến muộn\", khi mô hình tạo ra từ \"muộn\", nó chú ý nhiều đến \"anh ấy\" và \"đến\" để hiểu ai sẽ đến muộn.\n\n5. Quá trình tạo văn bản (Text Generation)\nKhi tạo văn bản, LLM dự đoán token tiếp theo dựa trên tất cả các token trước đó. Quá trình này lặp lại cho đến khi hoàn thành câu trả lời.\n\nVí dụ về quá trình tạo văn bản:\n\nĐầu vào: \"Thủ đô của Việt Nam là\"\nMô hình dự đoán token tiếp theo với xác suất cao nhất là \" Hà\"\nTiếp theo là \" Nội\"\nVà có thể là dấu chấm \".\"\n\n\nCác khái niệm quan trọng khác\n1. Tham số (Parameters)\nTham số là các giá trị số học mà mô hình học được trong quá trình huấn luyện. LLM hiện đại có hàng tỷ đến hàng nghìn tỷ tham số.\n\nVí dụ: GPT-3 có 175 tỷ tham số, Claude 3 Opus có khoảng 1 nghìn tỷ tham số.\n\n2. Context Window (Cửa sổ ngữ cảnh)\nContext window là số lượng token tối đa mà mô hình có thể xử lý cùng một lúc. Nó quyết định \"bộ nhớ\" của mô hình.\n\nVí dụ: Nếu một mô hình có context window 8K tokens, nó có thể \"nhớ\" và xử lý khoảng 6000-8000 từ tiếng Việt cùng một lúc.\n\n3. Temperature (Nhiệt độ)\nTemperature là tham số điều chỉnh mức độ ngẫu nhiên trong đầu ra của mô hình.\n\nVí dụ:\n\nTemperature thấp (0.2): \"Hà Nội là thủ đô của Việt Nam.\"\nTemperature cao (0.8): \"Hà Nội, thành phố nghìn năm văn hiến, là trái tim và thủ đô của đất nước Việt Nam xinh đẹp.\"\n\n4. Fine-tuning (Tinh chỉnh)\nFine-tuning là quá trình điều chỉnh mô hình đã được huấn luyện trước để phù hợp với nhiệm vụ cụ thể.\n\nVí dụ: Một LLM tổng quát có thể được fine-tune để trở thành trợ lý y tế bằng cách huấn luyện thêm trên dữ liệu y khoa.\n\n\nVí dụ minh họa về cách LLM xử lý văn bản\n\nGiả sử bạn hỏi: \"Làm thế nào để nấu phở bò?\"\n\nTokenization: Câu hỏi được chia thành các token: [\"Làm\", \" thế\", \" nào\", \" để\", \" nấu\", \" phở\", \" bò\", \"?\"]\nEmbedding: Mỗi token được chuyển đổi thành vector số học.\nXử lý qua các lớp Transformer: Mô hình xử lý các token thông qua nhiều lớp transformer, áp dụng cơ chế attention để hiểu ngữ cảnh.\nTạo câu trả lời: Mô hình bắt đầu tạo ra câu trả lời, token một:\nDự đoán token đầu tiên: \"Để\"\nTiếp theo: \" nấu\"\nTiếp theo: \" phở\"\nTiếp theo: \" bò\"\nTiếp theo: \" ngon\"\n...\nQuá trình này tiếp tục cho đến khi hoàn thành câu trả lời hoặc đạt đến giới hạn token.",
      "autoResize": true,
      "lineHeight": 1.35
    },
    {
      "type": "rectangle",
      "version": 2321,
      "versionNonce": 253795547,
      "isDeleted": false,
      "id": "epx-ZZXWWpIyr4d_ghTZz",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "angle": 0,
      "x": 1146.1315244017505,
      "y": -97.4355199300237,
      "strokeColor": "#000000",
      "backgroundColor": "transparent",
      "width": 1285.0504431715244,
      "height": 35.9493937139455,
      "seed": 113873595,
      "groupIds": [
        "oOCk23zT69zJBWuDrXorz"
      ],
      "index": "a6",
      "frameId": null,
      "roundness": null,
      "boundElements": [],
      "updated": 1745254067839,
      "link": null,
      "locked": false
    },
    {
      "id": "yHOoilPdTyl8CgSkjpxDf",
      "type": "line",
      "x": 1175.0880397616593,
      "y": -92.6401429260386,
      "width": 0.9716052355120405,
      "height": 26.233341358825093,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "a8",
      "roundness": {
        "type": 2
      },
      "seed": 1132370395,
      "version": 418,
      "versionNonce": 1749961083,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254067839,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          -0.9716052355120405,
          26.233341358825093
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": null,
      "endBinding": null,
      "startArrowhead": null,
      "endArrowhead": null
    },
    {
      "id": "DJDKCBBl_-k3dlXw1H0i-",
      "type": "line",
      "x": 1212.641931545249,
      "y": -93.46695966880065,
      "width": 0.9716052355120405,
      "height": 26.233341358825093,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "a9",
      "roundness": {
        "type": 2
      },
      "seed": 2091519387,
      "version": 444,
      "versionNonce": 1952277019,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254067839,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          -0.9716052355120405,
          26.233341358825093
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": null,
      "endBinding": null,
      "startArrowhead": null,
      "endArrowhead": null
    },
    {
      "id": "cTLlZubEeB6vzNrzu1qlf",
      "type": "line",
      "x": 1246.6481147881705,
      "y": -94.43856490431267,
      "width": 0.9716052355120405,
      "height": 26.233341358825093,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aA",
      "roundness": {
        "type": 2
      },
      "seed": 1177394517,
      "version": 441,
      "versionNonce": 742418107,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254067839,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          -0.9716052355120405,
          26.233341358825093
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": null,
      "endBinding": null,
      "startArrowhead": null,
      "endArrowhead": null
    },
    {
      "id": "vc8xsoBrNCbhZM-bfVTPk",
      "type": "line",
      "x": 1281.625903266604,
      "y": -93.46695966880043,
      "width": 0.9716052355120405,
      "height": 26.233341358825093,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aB",
      "roundness": {
        "type": 2
      },
      "seed": 661250267,
      "version": 442,
      "versionNonce": 1184487259,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254067839,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          -0.9716052355120405,
          26.233341358825093
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": null,
      "endBinding": null,
      "startArrowhead": null,
      "endArrowhead": null
    },
    {
      "id": "7F3gAs3N8qVP6IUrXaNPR",
      "type": "text",
      "x": 1292.6522732586159,
      "y": -91.66853769052659,
      "width": 87.71651947598546,
      "height": 24.290130887801013,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [
        "oOCk23zT69zJBWuDrXorz"
      ],
      "frameId": null,
      "index": "aC",
      "roundness": null,
      "seed": 67210421,
      "version": 407,
      "versionNonce": 29111291,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254067839,
      "link": null,
      "locked": false,
      "text": "... tokens",
      "fontSize": 19.43210471024081,
      "fontFamily": 5,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "... tokens",
      "autoResize": true,
      "lineHeight": 1.25
    },
    {
      "id": "nRztQ0dce0l5y5pKIN8TC",
      "type": "arrow",
      "x": 2087.425355907465,
      "y": -41.14506544390042,
      "width": 343.94825337126235,
      "height": 0,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aD",
      "roundness": {
        "type": 2
      },
      "seed": 1290910741,
      "version": 525,
      "versionNonce": 766114971,
      "isDeleted": false,
      "boundElements": [
        {
          "type": "text",
          "id": "x70FnV2fFxq8PgkyR2TRF"
        }
      ],
      "updated": 1745254067839,
      "link": null,
      "locked": false,
      "points": [
        [
          0,
          0
        ],
        [
          343.94825337126235,
          0
        ]
      ],
      "lastCommittedPoint": null,
      "startBinding": null,
      "endBinding": null,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "elbowed": false
    },
    {
      "id": "x70FnV2fFxq8PgkyR2TRF",
      "type": "text",
      "x": 1736.8794021606445,
      "y": 2048,
      "width": 148.16978454589844,
      "height": 24.290130887801013,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "aE",
      "roundness": null,
      "seed": 481511797,
      "version": 196,
      "versionNonce": 903519259,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254055026,
      "link": null,
      "locked": false,
      "text": "context window",
      "fontSize": 19.43210471024081,
      "fontFamily": 5,
      "textAlign": "center",
      "verticalAlign": "middle",
      "containerId": "nRztQ0dce0l5y5pKIN8TC",
      "originalText": "context window",
      "autoResize": true,
      "lineHeight": 1.25
    },
    {
      "id": "zVVVmH1m01gS4E7bTaa0z",
      "type": "text",
      "x": 671.12939453125,
      "y": 3135.5,
      "width": 990.059326171875,
      "height": 2862,
      "angle": 0,
      "strokeColor": "#1e1e1e",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "strokeStyle": "solid",
      "roughness": 1,
      "opacity": 100,
      "groupIds": [],
      "frameId": null,
      "index": "b0j",
      "roundness": null,
      "seed": 1023093371,
      "version": 47,
      "versionNonce": 908240117,
      "isDeleted": false,
      "boundElements": [],
      "updated": 1745254489007,
      "link": null,
      "locked": false,
      "text": "Các bước training dữ liệu cho LLM và đặc thù dữ liệu ở từng bước\n\n1. Pre-training (Huấn luyện trước)\n- Đặc thù dữ liệu:\n  + Khối lượng: Cực kỳ lớn, thường từ hàng trăm GB đến hàng TB văn bản\n  + Đa dạng: Bao gồm sách, bài báo, trang web, mã nguồn, bách khoa toàn thư, mạng xã hội...\n  + Đa ngôn ngữ: Nhiều ngôn ngữ khác nhau, với tiếng Anh thường chiếm tỷ lệ lớn\n  + Không cấu trúc: Dữ liệu thô, không được gán nhãn\n  + Chất lượng hỗn hợp: Từ văn bản chất lượng cao (sách, bài báo học thuật) đến nội dung chất lượng thấp hơn\n\n- Quy trình xử lý dữ liệu:\n  + Thu thập: Crawl web, tải xuống kho dữ liệu công khai (Common Crawl, C4, The Pile...)\n  + Làm sạch: Loại bỏ nội dung trùng lặp, spam, văn bản kém chất lượng\n  + Lọc: Áp dụng các bộ lọc để loại bỏ nội dung độc hại, phân biệt đối xử\n  + Tokenization: Chuyển đổi văn bản thành tokens để mô hình có thể xử lý\n\n- Mục tiêu:\n  + Dạy mô hình hiểu cấu trúc ngôn ngữ cơ bản\n  + Học các mối quan hệ thống kê giữa các từ và cụm từ\n  + Nắm bắt kiến thức tổng quát về thế giới\n\n2. Instruction Tuning (Tinh chỉnh theo hướng dẫn)\n- Đặc thù dữ liệu:\n  + Khối lượng: Nhỏ hơn nhiều so với pre-training, thường từ vài GB đến vài chục GB\n  + Cấu trúc: Dữ liệu có cấu trúc dạng cặp (instruction-response)\n  + Chất lượng: Được kiểm soát chặt chẽ, chất lượng cao\n  + Đa dạng nhiệm vụ: Bao gồm nhiều loại nhiệm vụ khác nhau (trả lời câu hỏi, tóm tắt, dịch thuật...)\n\n- Bộ dữ liệu phổ biến:\n  + Nhân tạo: Tạo ra bằng cách sử dụng LLM khác để sinh ra cặp instruction-response\n  + Con người tạo ra: Do con người viết hoặc đánh giá\n  + Kết hợp: Kết hợp cả hai phương pháp trên\n\n- Mục tiêu:\n  + Dạy mô hình cách làm theo hướng dẫn của người dùng\n  + Cải thiện khả năng trả lời hữu ích, chính xác\n  + Giảm thiểu phản hồi có hại hoặc không phù hợp\n\n3. RLHF (Reinforcement Learning from Human Feedback)\n- Đặc thù dữ liệu:\n  + Khối lượng: Tương đối nhỏ, thường vài GB\n  + Cấu trúc: Dữ liệu xếp hạng so sánh (preference data)\n  + Nguồn gốc: Đánh giá của con người hoặc mô hình đánh giá được huấn luyện\n  + Chất lượng: Rất cao, được kiểm soát chặt chẽ\n\n- Quy trình xử lý dữ liệu:\n  + Thu thập phản hồi: Con người xếp hạng các câu trả lời khác nhau cho cùng một câu hỏi\n  + Huấn luyện mô hình phần thưởng: Dự đoán câu trả lời nào được con người đánh giá cao hơn\n  + Tối ưu hóa chính sách: Sử dụng PPO (Proximal Policy Optimization) để tinh chỉnh mô hình\n\n- Mục tiêu:\n  + Điều chỉnh mô hình để tạo ra phản hồi phù hợp với giá trị và sở thích của con người\n  + Cải thiện tính hữu ích, trung thực và an toàn\n  + Giảm thiểu hallucination (bịa đặt) và nội dung có hại\n\n4. RLAIF (Reinforcement Learning from AI Feedback)\n- Đặc thù dữ liệu:\n  + Khối lượng: Có thể lớn hơn RLHF vì không bị giới hạn bởi đánh giá của con người\n  + Cấu trúc: Tương tự RLHF nhưng sử dụng AI làm người đánh giá\n  + Nguồn gốc: Đánh giá từ mô hình AI được huấn luyện để mô phỏng đánh giá của con người\n\n- Mục tiêu:\n  + Mở rộng quy mô của RLHF mà không cần quá nhiều đánh giá từ con người\n  + Tăng tốc quá trình tinh chỉnh\n  + Duy trì chất lượng tương tự như RLHF\n\n5. Domain-Specific Fine-tuning (Tinh chỉnh theo lĩnh vực cụ thể)\n- Đặc thù dữ liệu:\n  + Khối lượng: Nhỏ, thường từ vài MB đến vài GB\n  + Chuyên biệt: Tập trung vào một lĩnh vực cụ thể (y tế, luật, tài chính...)\n  + Cấu trúc: Có thể là dữ liệu có nhãn hoặc không có nhãn trong lĩnh vực đó\n  + Chất lượng: Thường rất cao, được chuyên gia trong lĩnh vực kiểm duyệt\n\n- Mục tiêu:\n  + Cải thiện hiệu suất của mô hình trong lĩnh vực cụ thể\n  + Học thuật ngữ chuyên ngành và kiến thức chuyên sâu\n  + Điều chỉnh phong cách và định dạng đầu ra phù hợp với lĩnh vực\n\n6. Alignment Tuning (Tinh chỉnh sự phù hợp)\n- Đặc thù dữ liệu:\n  + Khối lượng: Nhỏ, thường vài GB\n  + Nội dung: Tập trung vào các tình huống khó, đạo đức, an toàn\n  + Cấu trúc: Cặp câu hỏi-câu trả lời với hướng dẫn cụ thể về cách phản hồi\n  + Đa dạng: Bao gồm nhiều tình huống khác nhau để kiểm tra ranh giới của mô hình\n\n- Mục tiêu:\n  + Đảm bảo mô hình tuân thủ các giá trị và nguyên tắc đạo đức\n  + Giảm thiểu phản hồi có hại, sai lệch hoặc không phù hợp\n  + Cải thiện khả năng từ chối các yêu cầu không phù hợp\n\n7. Continual Learning (Học liên tục)\n- Đặc thù dữ liệu:\n  + Thời gian thực: Dữ liệu mới, cập nhật\n  + Đa dạng nguồn: Phản hồi người dùng, tin tức mới, kiến thức cập nhật\n  + Chọn lọc: Được lọc và kiểm duyệt cẩn thận\n\n- Mục tiêu:\n  + Cập nhật kiến thức của mô hình về các sự kiện hiện tại\n  + Điều chỉnh dựa trên phản hồi của người dùng\n  + Khắc phục các lỗi và hạn chế được phát hiện\n  + Đặc điểm chung của dữ liệu chất lượng cao cho LLM\n  + Đa dạng: Bao gồm nhiều chủ đề, phong cách, định dạng và ngôn ngữ\n  + Cân bằng: Không thiên vị về văn hóa, địa lý, ngôn ngữ hoặc quan điểm\n  + Chính xác: Thông tin chính xác, cập nhật và đáng tin cậy\n  + Đạo đức: Không chứa nội dung độc hại, phân biệt đối xử hoặc vi phạm quyền riêng tư\n  + Phù hợp: Phù hợp với mục tiêu và khả năng của mô hình",
      "fontSize": 20,
      "fontFamily": 6,
      "textAlign": "left",
      "verticalAlign": "top",
      "containerId": null,
      "originalText": "Các bước training dữ liệu cho LLM và đặc thù dữ liệu ở từng bước\n\n1. Pre-training (Huấn luyện trước)\n- Đặc thù dữ liệu:\n  + Khối lượng: Cực kỳ lớn, thường từ hàng trăm GB đến hàng TB văn bản\n  + Đa dạng: Bao gồm sách, bài báo, trang web, mã nguồn, bách khoa toàn thư, mạng xã hội...\n  + Đa ngôn ngữ: Nhiều ngôn ngữ khác nhau, với tiếng Anh thường chiếm tỷ lệ lớn\n  + Không cấu trúc: Dữ liệu thô, không được gán nhãn\n  + Chất lượng hỗn hợp: Từ văn bản chất lượng cao (sách, bài báo học thuật) đến nội dung chất lượng thấp hơn\n\n- Quy trình xử lý dữ liệu:\n  + Thu thập: Crawl web, tải xuống kho dữ liệu công khai (Common Crawl, C4, The Pile...)\n  + Làm sạch: Loại bỏ nội dung trùng lặp, spam, văn bản kém chất lượng\n  + Lọc: Áp dụng các bộ lọc để loại bỏ nội dung độc hại, phân biệt đối xử\n  + Tokenization: Chuyển đổi văn bản thành tokens để mô hình có thể xử lý\n\n- Mục tiêu:\n  + Dạy mô hình hiểu cấu trúc ngôn ngữ cơ bản\n  + Học các mối quan hệ thống kê giữa các từ và cụm từ\n  + Nắm bắt kiến thức tổng quát về thế giới\n\n2. Instruction Tuning (Tinh chỉnh theo hướng dẫn)\n- Đặc thù dữ liệu:\n  + Khối lượng: Nhỏ hơn nhiều so với pre-training, thường từ vài GB đến vài chục GB\n  + Cấu trúc: Dữ liệu có cấu trúc dạng cặp (instruction-response)\n  + Chất lượng: Được kiểm soát chặt chẽ, chất lượng cao\n  + Đa dạng nhiệm vụ: Bao gồm nhiều loại nhiệm vụ khác nhau (trả lời câu hỏi, tóm tắt, dịch thuật...)\n\n- Bộ dữ liệu phổ biến:\n  + Nhân tạo: Tạo ra bằng cách sử dụng LLM khác để sinh ra cặp instruction-response\n  + Con người tạo ra: Do con người viết hoặc đánh giá\n  + Kết hợp: Kết hợp cả hai phương pháp trên\n\n- Mục tiêu:\n  + Dạy mô hình cách làm theo hướng dẫn của người dùng\n  + Cải thiện khả năng trả lời hữu ích, chính xác\n  + Giảm thiểu phản hồi có hại hoặc không phù hợp\n\n3. RLHF (Reinforcement Learning from Human Feedback)\n- Đặc thù dữ liệu:\n  + Khối lượng: Tương đối nhỏ, thường vài GB\n  + Cấu trúc: Dữ liệu xếp hạng so sánh (preference data)\n  + Nguồn gốc: Đánh giá của con người hoặc mô hình đánh giá được huấn luyện\n  + Chất lượng: Rất cao, được kiểm soát chặt chẽ\n\n- Quy trình xử lý dữ liệu:\n  + Thu thập phản hồi: Con người xếp hạng các câu trả lời khác nhau cho cùng một câu hỏi\n  + Huấn luyện mô hình phần thưởng: Dự đoán câu trả lời nào được con người đánh giá cao hơn\n  + Tối ưu hóa chính sách: Sử dụng PPO (Proximal Policy Optimization) để tinh chỉnh mô hình\n\n- Mục tiêu:\n  + Điều chỉnh mô hình để tạo ra phản hồi phù hợp với giá trị và sở thích của con người\n  + Cải thiện tính hữu ích, trung thực và an toàn\n  + Giảm thiểu hallucination (bịa đặt) và nội dung có hại\n\n4. RLAIF (Reinforcement Learning from AI Feedback)\n- Đặc thù dữ liệu:\n  + Khối lượng: Có thể lớn hơn RLHF vì không bị giới hạn bởi đánh giá của con người\n  + Cấu trúc: Tương tự RLHF nhưng sử dụng AI làm người đánh giá\n  + Nguồn gốc: Đánh giá từ mô hình AI được huấn luyện để mô phỏng đánh giá của con người\n\n- Mục tiêu:\n  + Mở rộng quy mô của RLHF mà không cần quá nhiều đánh giá từ con người\n  + Tăng tốc quá trình tinh chỉnh\n  + Duy trì chất lượng tương tự như RLHF\n\n5. Domain-Specific Fine-tuning (Tinh chỉnh theo lĩnh vực cụ thể)\n- Đặc thù dữ liệu:\n  + Khối lượng: Nhỏ, thường từ vài MB đến vài GB\n  + Chuyên biệt: Tập trung vào một lĩnh vực cụ thể (y tế, luật, tài chính...)\n  + Cấu trúc: Có thể là dữ liệu có nhãn hoặc không có nhãn trong lĩnh vực đó\n  + Chất lượng: Thường rất cao, được chuyên gia trong lĩnh vực kiểm duyệt\n\n- Mục tiêu:\n  + Cải thiện hiệu suất của mô hình trong lĩnh vực cụ thể\n  + Học thuật ngữ chuyên ngành và kiến thức chuyên sâu\n  + Điều chỉnh phong cách và định dạng đầu ra phù hợp với lĩnh vực\n\n6. Alignment Tuning (Tinh chỉnh sự phù hợp)\n- Đặc thù dữ liệu:\n  + Khối lượng: Nhỏ, thường vài GB\n  + Nội dung: Tập trung vào các tình huống khó, đạo đức, an toàn\n  + Cấu trúc: Cặp câu hỏi-câu trả lời với hướng dẫn cụ thể về cách phản hồi\n  + Đa dạng: Bao gồm nhiều tình huống khác nhau để kiểm tra ranh giới của mô hình\n\n- Mục tiêu:\n  + Đảm bảo mô hình tuân thủ các giá trị và nguyên tắc đạo đức\n  + Giảm thiểu phản hồi có hại, sai lệch hoặc không phù hợp\n  + Cải thiện khả năng từ chối các yêu cầu không phù hợp\n\n7. Continual Learning (Học liên tục)\n- Đặc thù dữ liệu:\n  + Thời gian thực: Dữ liệu mới, cập nhật\n  + Đa dạng nguồn: Phản hồi người dùng, tin tức mới, kiến thức cập nhật\n  + Chọn lọc: Được lọc và kiểm duyệt cẩn thận\n\n- Mục tiêu:\n  + Cập nhật kiến thức của mô hình về các sự kiện hiện tại\n  + Điều chỉnh dựa trên phản hồi của người dùng\n  + Khắc phục các lỗi và hạn chế được phát hiện\n  + Đặc điểm chung của dữ liệu chất lượng cao cho LLM\n  + Đa dạng: Bao gồm nhiều chủ đề, phong cách, định dạng và ngôn ngữ\n  + Cân bằng: Không thiên vị về văn hóa, địa lý, ngôn ngữ hoặc quan điểm\n  + Chính xác: Thông tin chính xác, cập nhật và đáng tin cậy\n  + Đạo đức: Không chứa nội dung độc hại, phân biệt đối xử hoặc vi phạm quyền riêng tư\n  + Phù hợp: Phù hợp với mục tiêu và khả năng của mô hình",
      "autoResize": true,
      "lineHeight": 1.35
    }
  ],
  "appState": {
    "gridSize": 20,
    "gridStep": 5,
    "gridModeEnabled": false,
    "viewBackgroundColor": "#ffffff"
  },
  "files": {}
}